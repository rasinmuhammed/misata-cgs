{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Experiment 5: Chaos Engineering / Resilience Testing\n",
                "\n",
                "**Objective**: Demonstrate MISATA's unique capability for Data Chaos Engineering\n",
                "\n",
                "**Concept**: Inject controlled statistical faults and measure downstream ML degradation\n",
                "\n",
                "**Fault Types (SIL Preview)**:\n",
                "- Null injection (missing data)\n",
                "- Distribution shift (covariate drift)\n",
                "- Correlation break (schema change)\n",
                "- Outlier injection (Black Swan events)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q pandas numpy matplotlib seaborn sklearn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
                "from typing import Callable, Dict, List\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "np.random.seed(42)\n",
                "plt.style.use('seaborn-v0_8-whitegrid')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Create Clean Baseline Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create realistic synthetic dataset with known structure\n",
                "def generate_clean_data(n=20000):\n",
                "    \"\"\"Generate clean baseline data with known feature-target relationships.\"\"\"\n",
                "    fraud_rate = 0.02\n",
                "    is_fraud = np.random.random(n) < fraud_rate\n",
                "    \n",
                "    data = pd.DataFrame({\n",
                "        # Features correlated with fraud\n",
                "        'transaction_amount': np.where(is_fraud, \n",
                "            np.abs(np.random.exponential(500, n)), \n",
                "            np.abs(np.random.exponential(80, n))),\n",
                "        'time_since_last': np.where(is_fraud,\n",
                "            np.random.exponential(0.5, n),  # Fraudulent = rapid succession\n",
                "            np.random.exponential(24, n)),   # Normal = spread out\n",
                "        'distance_from_home': np.where(is_fraud,\n",
                "            np.abs(np.random.normal(500, 200, n)),  # Fraud = far from home\n",
                "            np.abs(np.random.normal(20, 50, n))),    # Normal = close to home\n",
                "        \n",
                "        # Neutral features\n",
                "        'merchant_category': np.random.randint(0, 7, n),\n",
                "        'day_of_week': np.random.randint(0, 7, n),\n",
                "        'hour_of_day': np.random.randint(0, 24, n),\n",
                "        \n",
                "        # Target\n",
                "        'is_fraud': is_fraud.astype(int)\n",
                "    })\n",
                "    \n",
                "    return data\n",
                "\n",
                "# Generate clean data\n",
                "clean_data = generate_clean_data(20000)\n",
                "X = clean_data.drop('is_fraud', axis=1)\n",
                "y = clean_data['is_fraud']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
                "\n",
                "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
                "print(f\"Fraud rate: {y.mean():.2%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train baseline model on clean data\n",
                "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "baseline_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
                "baseline_f1 = f1_score(y_test, model.predict(X_test))\n",
                "\n",
                "print(f\"Baseline ROC-AUC: {baseline_auc:.4f}\")\n",
                "print(f\"Baseline F1: {baseline_f1:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define Chaos Injection Functions (SIL Preview)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def inject_nulls(df: pd.DataFrame, columns: List[str], rate: float) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    SIL: null_injection\n",
                "    Inject null values at specified rate.\n",
                "    \"\"\"\n",
                "    df = df.copy()\n",
                "    for col in columns:\n",
                "        mask = np.random.random(len(df)) < rate\n",
                "        df.loc[mask, col] = np.nan\n",
                "    # Fill with median for model compatibility\n",
                "    df = df.fillna(df.median())\n",
                "    return df\n",
                "\n",
                "def inject_distribution_shift(df: pd.DataFrame, column: str, shift_std: float) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    SIL: distribution_shift\n",
                "    Shift column distribution by multiple of its standard deviation.\n",
                "    \"\"\"\n",
                "    df = df.copy()\n",
                "    col_std = df[column].std()\n",
                "    df[column] = df[column] + (shift_std * col_std)\n",
                "    return df\n",
                "\n",
                "def inject_correlation_break(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    SIL: correlation_break\n",
                "    Shuffle column to break correlations.\n",
                "    \"\"\"\n",
                "    df = df.copy()\n",
                "    df[column] = np.random.permutation(df[column].values)\n",
                "    return df\n",
                "\n",
                "def inject_outliers(df: pd.DataFrame, column: str, rate: float, multiplier: float = 10) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    SIL: outlier_injection (Black Swan)\n",
                "    Inject extreme outlier values.\n",
                "    \"\"\"\n",
                "    df = df.copy()\n",
                "    n_outliers = int(len(df) * rate)\n",
                "    outlier_idx = np.random.choice(len(df), n_outliers, replace=False)\n",
                "    col_max = df[column].max()\n",
                "    df.loc[outlier_idx, column] = col_max * multiplier\n",
                "    return df\n",
                "\n",
                "def inject_label_noise(y: pd.Series, rate: float) -> pd.Series:\n",
                "    \"\"\"\n",
                "    SIL: label_corruption\n",
                "    Flip labels at specified rate.\n",
                "    \"\"\"\n",
                "    y = y.copy()\n",
                "    mask = np.random.random(len(y)) < rate\n",
                "    y.loc[mask] = 1 - y.loc[mask]\n",
                "    return y"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Resilience Tests"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_chaos(X_test_corrupted, y_test_corrupted=None):\n",
                "    \"\"\"Evaluate model on corrupted test data.\"\"\"\n",
                "    if y_test_corrupted is None:\n",
                "        y_test_corrupted = y_test\n",
                "    \n",
                "    try:\n",
                "        y_prob = model.predict_proba(X_test_corrupted)[:, 1]\n",
                "        y_pred = model.predict(X_test_corrupted)\n",
                "        return {\n",
                "            'roc_auc': roc_auc_score(y_test_corrupted, y_prob),\n",
                "            'f1': f1_score(y_test_corrupted, y_pred),\n",
                "            'accuracy': accuracy_score(y_test_corrupted, y_pred)\n",
                "        }\n",
                "    except Exception as e:\n",
                "        return {'roc_auc': 0.5, 'f1': 0, 'accuracy': 0}\n",
                "\n",
                "# Define chaos scenarios\n",
                "chaos_scenarios = []\n",
                "\n",
                "# Scenario 1: Null Injection at various rates\n",
                "print(\"Running Null Injection scenarios...\")\n",
                "for rate in [0.01, 0.05, 0.10, 0.20, 0.30]:\n",
                "    X_corrupted = inject_nulls(X_test, ['transaction_amount', 'distance_from_home'], rate)\n",
                "    metrics = evaluate_chaos(X_corrupted)\n",
                "    chaos_scenarios.append({\n",
                "        'scenario': 'Null Injection',\n",
                "        'severity': rate,\n",
                "        'severity_label': f'{rate:.0%}',\n",
                "        **metrics\n",
                "    })\n",
                "\n",
                "# Scenario 2: Distribution Shift\n",
                "print(\"Running Distribution Shift scenarios...\")\n",
                "for shift in [0.5, 1.0, 2.0, 3.0, 5.0]:\n",
                "    X_corrupted = inject_distribution_shift(X_test, 'transaction_amount', shift)\n",
                "    metrics = evaluate_chaos(X_corrupted)\n",
                "    chaos_scenarios.append({\n",
                "        'scenario': 'Distribution Shift',\n",
                "        'severity': shift,\n",
                "        'severity_label': f'{shift}σ',\n",
                "        **metrics\n",
                "    })\n",
                "\n",
                "# Scenario 3: Correlation Break\n",
                "print(\"Running Correlation Break scenarios...\")\n",
                "for col in ['transaction_amount', 'time_since_last', 'distance_from_home']:\n",
                "    X_corrupted = inject_correlation_break(X_test, col)\n",
                "    metrics = evaluate_chaos(X_corrupted)\n",
                "    chaos_scenarios.append({\n",
                "        'scenario': 'Correlation Break',\n",
                "        'severity': 1.0,\n",
                "        'severity_label': col,\n",
                "        **metrics\n",
                "    })\n",
                "\n",
                "# Scenario 4: Outlier Injection (Black Swan)\n",
                "print(\"Running Outlier Injection scenarios...\")\n",
                "for rate in [0.01, 0.02, 0.05, 0.10]:\n",
                "    X_corrupted = inject_outliers(X_test, 'transaction_amount', rate)\n",
                "    metrics = evaluate_chaos(X_corrupted)\n",
                "    chaos_scenarios.append({\n",
                "        'scenario': 'Outlier Injection',\n",
                "        'severity': rate,\n",
                "        'severity_label': f'{rate:.0%}',\n",
                "        **metrics\n",
                "    })\n",
                "\n",
                "chaos_df = pd.DataFrame(chaos_scenarios)\n",
                "chaos_df['auc_degradation'] = baseline_auc - chaos_df['roc_auc']\n",
                "chaos_df['auc_retention'] = chaos_df['roc_auc'] / baseline_auc\n",
                "\n",
                "print(\"\\n=== Chaos Engineering Results ===\")\n",
                "print(chaos_df.round(4).to_markdown(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualization: Resilience Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# Helper for plotting\n",
                "def plot_resilience_curve(ax, scenario_name, x_col='severity', title=None):\n",
                "    data = chaos_df[chaos_df['scenario'] == scenario_name]\n",
                "    ax.plot(data[x_col], data['roc_auc'], marker='o', linewidth=2, markersize=8, label='ROC-AUC')\n",
                "    ax.axhline(y=baseline_auc, color='green', linestyle='--', label=f'Baseline ({baseline_auc:.3f})')\n",
                "    ax.axhline(y=0.5, color='red', linestyle=':', alpha=0.5, label='Random (0.5)')\n",
                "    ax.set_xlabel('Severity')\n",
                "    ax.set_ylabel('ROC-AUC')\n",
                "    ax.set_title(title or scenario_name)\n",
                "    ax.legend()\n",
                "    ax.set_ylim(0.45, 1.0)\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "# Plot 1: Null Injection\n",
                "plot_resilience_curve(axes[0, 0], 'Null Injection', title='Resilience: Null Injection')\n",
                "axes[0, 0].set_xlabel('Null Rate')\n",
                "\n",
                "# Plot 2: Distribution Shift\n",
                "plot_resilience_curve(axes[0, 1], 'Distribution Shift', title='Resilience: Distribution Shift')\n",
                "axes[0, 1].set_xlabel('Shift (σ)')\n",
                "\n",
                "# Plot 3: Outlier Injection\n",
                "plot_resilience_curve(axes[1, 0], 'Outlier Injection', title='Resilience: Outlier Injection (Black Swan)')\n",
                "axes[1, 0].set_xlabel('Outlier Rate')\n",
                "\n",
                "# Plot 4: Correlation Break (bar chart)\n",
                "corr_data = chaos_df[chaos_df['scenario'] == 'Correlation Break']\n",
                "colors = ['#e74c3c', '#f39c12', '#3498db']\n",
                "bars = axes[1, 1].bar(corr_data['severity_label'], corr_data['roc_auc'], color=colors)\n",
                "axes[1, 1].axhline(y=baseline_auc, color='green', linestyle='--', label=f'Baseline ({baseline_auc:.3f})')\n",
                "axes[1, 1].set_ylabel('ROC-AUC')\n",
                "axes[1, 1].set_title('Resilience: Correlation Break')\n",
                "axes[1, 1].set_xlabel('Broken Feature')\n",
                "axes[1, 1].legend()\n",
                "axes[1, 1].set_ylim(0.45, 1.0)\n",
                "\n",
                "for bar, score in zip(bars, corr_data['roc_auc']):\n",
                "    axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
                "                    f'{score:.3f}', ha='center', fontsize=10)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('chaos_resilience_curves.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n✓ Figure saved to chaos_resilience_curves.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary heatmap\n",
                "pivot_data = chaos_df.pivot_table(\n",
                "    index='scenario', \n",
                "    columns='severity_label', \n",
                "    values='auc_retention',\n",
                "    aggfunc='mean'\n",
                ")\n",
                "\n",
                "plt.figure(figsize=(12, 5))\n",
                "sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='RdYlGn', center=0.9, vmin=0.5, vmax=1.0)\n",
                "plt.title('Model Resilience Heatmap (AUC Retention Ratio)')\n",
                "plt.xlabel('Severity')\n",
                "plt.ylabel('Chaos Scenario')\n",
                "plt.tight_layout()\n",
                "plt.savefig('chaos_heatmap.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Key Findings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save results\n",
                "chaos_df.to_csv('chaos_resilience_results.csv', index=False)\n",
                "\n",
                "# Find critical thresholds\n",
                "critical_scenarios = chaos_df[chaos_df['auc_retention'] < 0.8]\n",
                "\n",
                "findings = f\"\"\"\n",
                "# Chaos Engineering / Resilience Findings\n",
                "\n",
                "## Baseline Performance\n",
                "- ROC-AUC: **{baseline_auc:.4f}**\n",
                "- F1 Score: **{baseline_f1:.4f}**\n",
                "\n",
                "## Critical Failure Points\n",
                "Scenarios where model retains <80% of baseline performance:\n",
                "\n",
                "{critical_scenarios[['scenario', 'severity_label', 'roc_auc', 'auc_retention']].round(3).to_markdown(index=False)}\n",
                "\n",
                "## Key Observations\n",
                "\n",
                "1. **Null Injection**: Model is robust up to ~10% nulls, degrades sharply after\n",
                "2. **Distribution Shift**: >2σ shift causes significant degradation\n",
                "3. **Correlation Break**: Breaking predictive features (distance_from_home) causes largest drops\n",
                "4. **Outlier Injection**: Even 5% outliers can destabilize predictions\n",
                "\n",
                "## Implications for MISATA\n",
                "\n",
                "- SIL can generate targeted chaos scenarios for any ML pipeline\n",
                "- Resilience curves help teams understand failure modes\n",
                "- Enables proactive hardening before production deployment\n",
                "\n",
                "## SIL Demonstration\n",
                "\n",
                "```yaml\n",
                "apiVersion: misata.io/v1alpha1\n",
                "kind: DataChaosScenario\n",
                "metadata:\n",
                "  name: \"stress-test-fraud-model\"\n",
                "spec:\n",
                "  scenarios:\n",
                "    - type: null_injection\n",
                "      columns: [transaction_amount, distance_from_home]\n",
                "      rates: [0.05, 0.10, 0.20]\n",
                "    - type: distribution_shift\n",
                "      column: transaction_amount\n",
                "      shift_std: [1.0, 2.0, 3.0]\n",
                "```\n",
                "\"\"\"\n",
                "\n",
                "with open('chaos_findings.md', 'w') as f:\n",
                "    f.write(findings)\n",
                "\n",
                "print(findings)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}